{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G28ynkon-QY1"
      },
      "source": [
        "# Artificial Neural Networks and Deep Learning    \n",
        "## Assignment 3.1 - Autoencoders and Stacked Autoencoders\n",
        "\n",
        "Prof. Dr. Ir. Johan A. K. Suykens     \n",
        "\n",
        "In this file, we will implement two network architectures from scratch: (1) Autoencoders; (2) Stacked Autoencoders.\n",
        "\n",
        "We will train both networks on the MNIST dataset under reconstruction learning task. All training will be conducted on a single T4 GPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZHATEBH-INR"
      },
      "outputs": [],
      "source": [
        "# Please first load your google drive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnZZO_oOFpJP"
      },
      "outputs": [],
      "source": [
        "# Please go to Edit > Notebook settings > Hardware accelerator > choose \"T4 GPU\"\n",
        "# Now check if you have loaded the GPU successfully\n",
        "# !nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "504PW8Go_Bna"
      },
      "source": [
        "# Autoencoder\n",
        "In this section, we implement an Autoencoder from scratch and trainit on the MNIST dataset. With this autoencoder, we pass input data through an encoder making a compressed representation of the input, and then pass this representation to the following decoder to reconstruct the input data.\n",
        "Note that in this exercise session we will be using  ``PyTorch`` instead of ``Keras`` for building and training our neural networks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eGwR7aL5_FSD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Set the seed for reproducibility. Don't forget to comment out this line when averaging over different runs\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Convert data to torch.FloatTensor\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "\n",
        "train_data = datasets.MNIST(root='data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Select only a part of the dataset to speed up training times\n",
        "num_train_samples = 10000\n",
        "num_test_samples = 1000\n",
        "\n",
        "# Randomly select a subset of samples\n",
        "train_indices = torch.randperm(len(train_data))[:num_train_samples]\n",
        "test_indices = torch.randperm(len(test_data))[:num_test_samples]\n",
        "\n",
        "# Create subset samplers to be used in the dataloader\n",
        "train_subset_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "test_subset_sampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OxiS9KN9oQA"
      },
      "source": [
        "## Create training and test dataloaders\n",
        "\n",
        "\n",
        "Dataloaders are used for efficiently loading, batching, and managing datasets in PyTorch.\n",
        "During training dataloaders feed the data into the network batch by batch instead of the whole dataset at once. This allows us to handle larger datasets without running out of memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Lig-NUzmAuiZ"
      },
      "outputs": [],
      "source": [
        "# Choose how many samples per batch to load\n",
        "# You can tune the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Prepare data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                           batch_size=batch_size,\n",
        "                                           sampler = train_subset_sampler,\n",
        "                                           num_workers=0)\n",
        "test_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                          batch_size=batch_size,\n",
        "                                          sampler = test_subset_sampler,\n",
        "                                          num_workers=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk4UCmCdBjjZ"
      },
      "source": [
        "## Visualize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3BeTdD4yBcl9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x18cd25ffbd0>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Obtain one batch of training images\n",
        "images, labels = next(iter(train_loader)) # iter() creates an iterator over the batches in the dataloader and next() selects the next batch from this iterator.\n",
        "images = images.numpy() #.numpy() turns the torch.tensor into a numpy array\n",
        "\n",
        "# Get one image from the batch\n",
        "img = np.squeeze(images[0])\n",
        "\n",
        "fig = plt.figure(figsize = (5,5))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.imshow(img, cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzWxOoXYCUiz"
      },
      "source": [
        "## Build the Linear Autoencoder\n",
        "We now train a linear autoencoder on MINIST dataset.\n",
        "Images of original size 28$\\times$28 will be flattened into 784-dimensional vectors.\n",
        "Note that images from this dataset are already normalized so that the values are between 0 and 1.\n",
        "Since the images are normalized between 0 and 1, we need to use a sigmoid activation on the output layer to get values that match this input value range.\n",
        "\n",
        "The encoder and decoder in the Autoencoder are built with one linear layer where you can tune the dimension of the hidden representation, i.e., ``encoding_dim``, to obtain models with different size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "05JucJsoB6E-"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the NN architecture\n",
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self, encoding_dim):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        # Encoder\n",
        "        self.encoder = nn.Linear(784, encoding_dim)\n",
        "        # Decoder\n",
        "        self.decoder = nn.Linear(encoding_dim, 784)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Define feedforward behavior\n",
        "        # and scale the *output* layer with a sigmoid activation function\n",
        "\n",
        "        # Pass x into encoder\n",
        "        out = F.relu(self.encoder(x))\n",
        "        # Pass out into decoder\n",
        "        out = torch.sigmoid(self.decoder(out))\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FtBYi-kACg1A"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Autoencoder(\n",
            "  (encoder): Linear(in_features=784, out_features=32, bias=True)\n",
            "  (decoder): Linear(in_features=32, out_features=784, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Initialize the NN\n",
        "# You can change the encoding_dim to obtain models with different size\n",
        "encoding_dim = 32\n",
        "model = Autoencoder(encoding_dim)\n",
        "\n",
        "# Send model to GPU if available\n",
        "if torch.cuda.is_available():\n",
        "  model.cuda()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6oAhmIwEDgo"
      },
      "source": [
        "## Training on MNIST\n",
        "Training a neural network in PyTorch involves manually defining the training loop.\n",
        "Here data processing, forward pass, loss computation, and optimization are explicitly specified.\n",
        "\n",
        "Since we work on reconstruction learning tasks, we do not need the labels here but only the images.\n",
        "The loss function should choose the MSE loss for reconstruction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ssUxyRJSEUzV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0 \tTraining Loss: 2.386593\n",
            "Epoch: 1 \tTraining Loss: 1.315528\n",
            "Epoch: 2 \tTraining Loss: 1.040680\n",
            "Epoch: 3 \tTraining Loss: 0.878057\n",
            "Epoch: 4 \tTraining Loss: 0.759522\n",
            "Epoch: 5 \tTraining Loss: 0.688439\n",
            "Epoch: 6 \tTraining Loss: 0.636693\n",
            "Epoch: 7 \tTraining Loss: 0.597742\n",
            "Epoch: 8 \tTraining Loss: 0.568476\n",
            "Epoch: 9 \tTraining Loss: 0.546332\n",
            "Epoch: 10 \tTraining Loss: 0.530176\n",
            "Epoch: 11 \tTraining Loss: 0.518377\n",
            "Epoch: 12 \tTraining Loss: 0.509132\n",
            "Epoch: 13 \tTraining Loss: 0.501971\n",
            "Epoch: 14 \tTraining Loss: 0.495893\n",
            "Epoch: 15 \tTraining Loss: 0.491787\n",
            "Epoch: 16 \tTraining Loss: 0.488524\n",
            "Epoch: 17 \tTraining Loss: 0.485783\n",
            "Epoch: 18 \tTraining Loss: 0.483460\n",
            "Epoch: 19 \tTraining Loss: 0.480828\n"
          ]
        }
      ],
      "source": [
        "# Specify the loss function\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# We use Adam as the optimizer with a fixed learning rate of 1e-3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Choose the number of Epochs to train the network\n",
        "n_epochs = 20\n",
        "# Set model to training mode\n",
        "model.train()\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # Monitor training loss\n",
        "    train_loss = 0.0\n",
        "\n",
        "    # Train the model #\n",
        "    # Feed the data into the network batch by batch using the dataloader\n",
        "    for batch_data in train_loader:\n",
        "        # _ stands in for labels\n",
        "        # we do not need labels when conducting reconstruction\n",
        "        images, _ = batch_data\n",
        "        # Flatten images and send images to GPU\n",
        "        images = images.view(images.size(0), -1)\n",
        "        # Send images to GPU if possible\n",
        "        if torch.cuda.is_available():\n",
        "          images = images.cuda()\n",
        "        # Clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
        "        outputs = model(images)\n",
        "        # Calculate the loss between output and input images\n",
        "        loss = criterion(outputs, images)\n",
        "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # Perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # Update running training loss\n",
        "        train_loss += loss.item()*images.size(0)\n",
        "\n",
        "    # Print avg training statistics\n",
        "    train_loss = train_loss/len(train_loader)\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
        "        epoch,\n",
        "        train_loss\n",
        "        ))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeN_f28fJ1lq"
      },
      "source": [
        "## Evaluation on test set\n",
        "We now evaluate the reconstruction results on the unseen test set.\n",
        "We plot the original test images and their corresponding reconstruction ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "daly1tTfbbXk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.001470\n"
          ]
        }
      ],
      "source": [
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Monitor test loss\n",
        "test_loss = 0.0\n",
        "\n",
        "# Disable gradient computation\n",
        "with torch.no_grad():\n",
        "    # Iterate over the test data\n",
        "    for batch_data in test_loader:\n",
        "        # Extract images from the batch\n",
        "        images, _ = batch_data\n",
        "        # Flatten images and send them to GPU\n",
        "        images = images.view(images.size(0), -1)\n",
        "        # Send to GPU\n",
        "        if torch.cuda.is_available():\n",
        "          images = images.cuda()\n",
        "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
        "        outputs = model(images)\n",
        "        # Calculate the loss between output and input images\n",
        "        loss = criterion(outputs, images)\n",
        "        # Update test loss\n",
        "        test_loss += loss.item()*images.size(0)\n",
        "\n",
        "# Compute average test loss\n",
        "test_loss = test_loss/len(test_loader.dataset)\n",
        "\n",
        "# Print test loss\n",
        "print('Test Loss: {:.6f}'.format(test_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gemBn0ihG2Yo"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2500x400 with 20 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Obtain one batch of test images\n",
        "test_images, test_labels = next(iter(test_loader))\n",
        "\n",
        "test_images_flatten = test_images.view(test_images.size(0), -1)\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "# Send model back to CPU\n",
        "model.cpu()\n",
        "# Get sample outputs\n",
        "output = model(test_images_flatten)\n",
        "# Prep images for display\n",
        "test_images = test_images.numpy()\n",
        "\n",
        "# Output is resized into a batch of images\n",
        "output = output.view(batch_size, 1, 28, 28)\n",
        "# Use detach when it's an output that requires_grad\n",
        "output = output.detach().numpy()\n",
        "\n",
        "# Plot the first ten input images and then reconstructed images\n",
        "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))\n",
        "\n",
        "# Input images on top row, reconstructions on bottom\n",
        "for test_images, row in zip([test_images, output], axes):\n",
        "    for img, ax in zip(test_images, row):\n",
        "        ax.imshow(np.squeeze(img), cmap='gray')\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVYXhsPrLBrV"
      },
      "source": [
        "# Stacked Autoencoder\n",
        "In this section, we implement the Stacked Autoencoder from scratch and train it on the MNIST dataset.\n",
        "The training process is with two steps: (1) each layer is trained separately; (2) the network is trained as a whole.\n",
        "\n",
        "We first load the dataset as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8163o-y3SLfw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim, functional, utils\n",
        "\n",
        "from torch.nn import BCELoss, init\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, utils\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "import time, os\n",
        "\n",
        "# We automate the dataloading process for future use\n",
        "def get_mnist_loader(batch_size=32, num_train_samples = 6000, num_test_samples = 1000):\n",
        "    \"\"\"\n",
        "\n",
        "    :return: train_loader, test_loader\n",
        "    \"\"\"\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
        "    transforms.Normalize((0.0,), (1.0,))  # Normalize the tensor with mean 0 and standard deviation 1\n",
        "    ])\n",
        "    train_dataset = MNIST(root='../data',\n",
        "                          train=True,\n",
        "                          transform=transform,\n",
        "                          download=True)\n",
        "    test_dataset = MNIST(root='../data',\n",
        "                         train=False,\n",
        "                         transform=transform,\n",
        "                         download=True)\n",
        "\n",
        "    # Randomly select a subset of samples\n",
        "    train_indices = torch.randperm(len(train_dataset))[:num_train_samples]\n",
        "    test_indices = torch.randperm(len(test_dataset))[:num_test_samples]\n",
        "\n",
        "    # Create subset samplers to be used in the dataloader\n",
        "    train_subset_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
        "    test_subset_sampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                               batch_size=batch_size,\n",
        "                                               sampler = train_subset_sampler)\n",
        "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                              batch_size=batch_size,\n",
        "                                              sampler = test_subset_sampler)\n",
        "    return train_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GimciNoQI73"
      },
      "source": [
        "## Build the Stacked Autoencoder\n",
        "Before building the Stacked Autoencoder, we need to build the Autoencoder layer first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TNjUD_jNLDN3"
      },
      "outputs": [],
      "source": [
        "class AutoEncoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    fully-connected linear layers for stacked autoencoders.\n",
        "    This module can automatically be trained when training each layer is enabled\n",
        "    Yes, this is much like the simplest auto-encoder\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim=None, hidden_dim=None, SelfTraining=False):\n",
        "        super(AutoEncoderLayer, self).__init__()\n",
        "        # If input_dim is None or hidden_dim is None:\n",
        "        # raise ValueError\n",
        "        self.in_features = input_dim\n",
        "        self.out_features = hidden_dim\n",
        "        # Whether to conduct layer-by-layer pre-training, or train the entire network\n",
        "        self.is_training_self = SelfTraining\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(self.in_features, self.out_features, bias=True),\n",
        "            nn.Sigmoid()  # use Sigmoid activation function\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(self.out_features, self.in_features, bias=True),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        #self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.encoder(x)\n",
        "        if self.is_training_self:\n",
        "            return self.decoder(out) # If the layer is not in training mode, it will just encode the data and pass it through\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "    def lock_grad(self):\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def acquire_grad(self):\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    @property\n",
        "    def input_dim(self):\n",
        "        return self.in_features\n",
        "\n",
        "    @property\n",
        "    def output_dim(self):\n",
        "        return self.out_features\n",
        "\n",
        "    @property\n",
        "    def is_training_layer(self):\n",
        "        return self.is_training_self\n",
        "\n",
        "    @is_training_layer.setter\n",
        "    def is_training_layer(self, other: bool):\n",
        "        self.is_training_self = other"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxT2upS1Aee6"
      },
      "source": [
        "## Build the stacked autoencoder\n",
        "\n",
        "Here we stack the autoencoder layers together and add a classification layer at the end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dw1r8BdBpO5f"
      },
      "outputs": [],
      "source": [
        "class StackedAutoEncoderClassifier(nn.Module):\n",
        "    \"\"\"\n",
        "    Stack the trained autoencoder layers and add a classification layer at the end\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, autoencoder_list=None, num_classes=10):\n",
        "        super(StackedAutoEncoderClassifier, self).__init__()\n",
        "        # Use only the encoder parts of the autoencoders\n",
        "        self.encoder_layers = nn.ModuleList([autoencoder.encoder for autoencoder in autoencoder_list])\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Classification layer\n",
        "        self.classification_layer = nn.Linear(autoencoder_list[-1].out_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded_representation = x\n",
        "        for layer in self.encoder_layers:\n",
        "            encoded_representation = layer(encoded_representation)\n",
        "\n",
        "        # Classification layer\n",
        "        output = self.classification_layer(encoded_representation)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UQL0TzMRxc3"
      },
      "source": [
        "## The training function of each layer\n",
        "We need to freeze the parameters in the previous layers when training the current layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pvZYBFsGRsmg"
      },
      "outputs": [],
      "source": [
        "def train_layer(layers_list=None, layer=None, epochs=None, validate=True, batch_size = 128):\n",
        "    \"\"\"\n",
        "    Greedy layer-wise training: when training the i-th layer, freeze the i-1 layer\n",
        "    :param layers_list:\n",
        "    :param layer:\n",
        "    :param epoch:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        for model in layers_list:\n",
        "            model.cuda()\n",
        "\n",
        "    train_loader, test_loader = get_mnist_loader(batch_size=batch_size)\n",
        "    optimizer = optim.SGD(layers_list[layer].parameters(), lr=0.1)\n",
        "    criterion = torch.nn.MSELoss()\n",
        "\n",
        "    # Train\n",
        "    for epoch_index in range(epochs):\n",
        "        sum_loss = 0.\n",
        "\n",
        "        # Freeze the parameters of all layers before the current layer\n",
        "        # Layer 0 has no previous layer\n",
        "        if layer != 0:\n",
        "            for index in range(layer):\n",
        "                # In addition to freezing parameters\n",
        "                # the output return method of the frozen layer must also be set.\n",
        "                layers_list[index].lock_grad()\n",
        "                layers_list[index].is_training_layer = False\n",
        "\n",
        "        for batch_index, (train_data, _) in enumerate(train_loader):\n",
        "            # Generate input data\n",
        "            if torch.cuda.is_available():\n",
        "                train_data = train_data.cuda()  # Put data onto GPU\n",
        "            out = train_data.view(train_data.size(0), -1)\n",
        "\n",
        "            # Perform forward calculation on the frozen layers before (layer-1)-th layer\n",
        "            if layer != 0:\n",
        "                for l in range(layer):\n",
        "                    out = layers_list[l](out)\n",
        "\n",
        "            # Train the layer-th layer\n",
        "            pred = layers_list[layer](out)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(pred, out)\n",
        "            sum_loss += loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            #if (batch_index + 1) % 20 == 0:\n",
        "        print(\"Train Layer: {}, Epoch: {}/{}, Iter: {}/{}, Loss: {:.4f}\".format(\n",
        "            layer, (epoch_index + 1), epochs, (batch_index + 1), len(train_loader), loss))\n",
        "\n",
        "        if validate:\n",
        "            pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzOYc3BWx1WY"
      },
      "source": [
        "## The training function of the whole network\n",
        "Now we unfreeze all the parameters in the network that are previously frozen for the layer training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LaK2zTZd2Z5Z"
      },
      "outputs": [],
      "source": [
        "def train_classifier(model=None, epochs=20, fine_tuning = False, batch_size = 128):\n",
        "\n",
        "    print(\">> start training whole model\")\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "\n",
        "    # unfreeze the parameters frozen in pre-training if needed\n",
        "    if fine_tuning:\n",
        "      for param in model.parameters():\n",
        "          param.requires_grad = True\n",
        "      training_phase = 'Fine-Tuning'\n",
        "    else:\n",
        "      training_phase = 'Classifier'\n",
        "\n",
        "    train_loader, test_loader = get_mnist_loader(batch_size=batch_size)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=1)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Set the model to training mode\n",
        "    model.train()\n",
        "\n",
        "    # train\n",
        "    for epoch_index in range(epochs):\n",
        "        sum_loss = 0.\n",
        "        for batch_index, (train_data, train_labels) in enumerate(train_loader):\n",
        "            if torch.cuda.is_available():\n",
        "                train_data, train_labels = train_data.cuda(), train_labels.cuda()\n",
        "            x = train_data.view(train_data.size(0), -1)\n",
        "\n",
        "            predicted_labels = model(x)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(predicted_labels, train_labels)\n",
        "            sum_loss += loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(\"Train {}, Epoch: {}/{}, Iter: {}/{}, Loss: {:.4f}\".format(training_phase, (epoch_index + 1), epochs, (batch_index + 1), len(train_loader), loss))\n",
        "\n",
        "    print(\"<< end training whole model\")\n",
        "    print(\"Calculating accuracy on the whole test set\")\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Calculate accuracy on the test set\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_data in test_loader:\n",
        "            images, labels = batch_data\n",
        "            images = images.view(images.size(0), -1)\n",
        "            if torch.cuda.is_available():\n",
        "              images, labels = images.cuda(), labels.cuda()\n",
        "            outputs = model(images)\n",
        "            # Get the highest value for each point to get the label\n",
        "            _, predicted_labels = torch.max(outputs.data, 1)\n",
        "            # Count number of correct predictions in the batch\n",
        "            total_correct += (predicted_labels == labels).sum().item()\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "\n",
        "    # Compute average test loss\n",
        "    accuracy = total_correct / total_samples\n",
        "    print('Accuracy on the test set: {:.6f}'.format(accuracy))\n",
        "    return model, accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkccSfRJx4ah"
      },
      "source": [
        "## Let's start training!\n",
        "The default network is trained with layer epochs 10, classifier epochs 10, fine-tuning epochs 20, batch size of 128. You can try to change the hyper-parameters to obtain better reconstruction performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zm44Cap4T7oS"
      },
      "outputs": [],
      "source": [
        "# You can change the hyper-parameters here\n",
        "# Be sure to try out different combinations of epochs for the pretraining and fine-tuning\n",
        "num_layer_wise_epochs = 10\n",
        "num_classifier_epochs = 10\n",
        "num_finetuning_epochs = 20\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "M6N2XhTqT_-X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ../data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ../data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ../data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ../data\\MNIST\\raw\n",
            "\n",
            "Train Layer: 0, Epoch: 1/10, Iter: 47/47, Loss: 0.2208\n",
            "Train Layer: 0, Epoch: 2/10, Iter: 47/47, Loss: 0.2071\n",
            "Train Layer: 0, Epoch: 3/10, Iter: 47/47, Loss: 0.1944\n",
            "Train Layer: 0, Epoch: 4/10, Iter: 47/47, Loss: 0.1827\n",
            "Train Layer: 0, Epoch: 5/10, Iter: 47/47, Loss: 0.1725\n",
            "Train Layer: 0, Epoch: 6/10, Iter: 47/47, Loss: 0.1625\n",
            "Train Layer: 0, Epoch: 7/10, Iter: 47/47, Loss: 0.1548\n",
            "Train Layer: 0, Epoch: 8/10, Iter: 47/47, Loss: 0.1461\n",
            "Train Layer: 0, Epoch: 9/10, Iter: 47/47, Loss: 0.1393\n",
            "Train Layer: 0, Epoch: 10/10, Iter: 47/47, Loss: 0.1329\n",
            "Train Layer: 1, Epoch: 1/10, Iter: 47/47, Loss: 0.0082\n",
            "Train Layer: 1, Epoch: 2/10, Iter: 47/47, Loss: 0.0076\n",
            "Train Layer: 1, Epoch: 3/10, Iter: 47/47, Loss: 0.0073\n",
            "Train Layer: 1, Epoch: 4/10, Iter: 47/47, Loss: 0.0066\n",
            "Train Layer: 1, Epoch: 5/10, Iter: 47/47, Loss: 0.0064\n",
            "Train Layer: 1, Epoch: 6/10, Iter: 47/47, Loss: 0.0058\n",
            "Train Layer: 1, Epoch: 7/10, Iter: 47/47, Loss: 0.0055\n",
            "Train Layer: 1, Epoch: 8/10, Iter: 47/47, Loss: 0.0053\n",
            "Train Layer: 1, Epoch: 9/10, Iter: 47/47, Loss: 0.0049\n",
            "Train Layer: 1, Epoch: 10/10, Iter: 47/47, Loss: 0.0047\n",
            "StackedAutoEncoderClassifier(\n",
            "  (encoder_layers): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Linear(in_features=784, out_features=256, bias=True)\n",
            "      (1): Sigmoid()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Linear(in_features=256, out_features=64, bias=True)\n",
            "      (1): Sigmoid()\n",
            "    )\n",
            "  )\n",
            "  (classification_layer): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            ">> start training whole model\n",
            "Train Classifier, Epoch: 1/10, Iter: 47/47, Loss: 2.3036\n",
            "Train Classifier, Epoch: 2/10, Iter: 47/47, Loss: 2.2820\n",
            "Train Classifier, Epoch: 3/10, Iter: 47/47, Loss: 2.2851\n",
            "Train Classifier, Epoch: 4/10, Iter: 47/47, Loss: 2.3084\n",
            "Train Classifier, Epoch: 5/10, Iter: 47/47, Loss: 2.2853\n",
            "Train Classifier, Epoch: 6/10, Iter: 47/47, Loss: 2.2420\n",
            "Train Classifier, Epoch: 7/10, Iter: 47/47, Loss: 2.2863\n",
            "Train Classifier, Epoch: 8/10, Iter: 47/47, Loss: 2.2656\n",
            "Train Classifier, Epoch: 9/10, Iter: 47/47, Loss: 2.1700\n",
            "Train Classifier, Epoch: 10/10, Iter: 47/47, Loss: 2.1678\n",
            "<< end training whole model\n",
            "Calculating accuracy on the whole test set\n",
            "Accuracy on the test set: 0.121000\n",
            ">> start training whole model\n",
            "Train Fine-Tuning, Epoch: 1/20, Iter: 47/47, Loss: 0.9376\n",
            "Train Fine-Tuning, Epoch: 2/20, Iter: 47/47, Loss: 0.8935\n",
            "Train Fine-Tuning, Epoch: 3/20, Iter: 47/47, Loss: 0.4706\n",
            "Train Fine-Tuning, Epoch: 4/20, Iter: 47/47, Loss: 0.4652\n",
            "Train Fine-Tuning, Epoch: 5/20, Iter: 47/47, Loss: 0.4770\n",
            "Train Fine-Tuning, Epoch: 6/20, Iter: 47/47, Loss: 0.2215\n",
            "Train Fine-Tuning, Epoch: 7/20, Iter: 47/47, Loss: 0.2335\n",
            "Train Fine-Tuning, Epoch: 8/20, Iter: 47/47, Loss: 0.2620\n",
            "Train Fine-Tuning, Epoch: 9/20, Iter: 47/47, Loss: 0.3046\n",
            "Train Fine-Tuning, Epoch: 10/20, Iter: 47/47, Loss: 0.2484\n",
            "Train Fine-Tuning, Epoch: 11/20, Iter: 47/47, Loss: 0.2255\n",
            "Train Fine-Tuning, Epoch: 12/20, Iter: 47/47, Loss: 0.4824\n",
            "Train Fine-Tuning, Epoch: 13/20, Iter: 47/47, Loss: 0.4164\n",
            "Train Fine-Tuning, Epoch: 14/20, Iter: 47/47, Loss: 0.2657\n",
            "Train Fine-Tuning, Epoch: 15/20, Iter: 47/47, Loss: 0.2651\n",
            "Train Fine-Tuning, Epoch: 16/20, Iter: 47/47, Loss: 0.0961\n",
            "Train Fine-Tuning, Epoch: 17/20, Iter: 47/47, Loss: 0.1357\n",
            "Train Fine-Tuning, Epoch: 18/20, Iter: 47/47, Loss: 0.1799\n",
            "Train Fine-Tuning, Epoch: 19/20, Iter: 47/47, Loss: 0.1537\n",
            "Train Fine-Tuning, Epoch: 20/20, Iter: 47/47, Loss: 0.1718\n",
            "<< end training whole model\n",
            "Calculating accuracy on the whole test set\n",
            "Accuracy on the test set: 0.918000\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Parent directory ./models does not exist.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 28\u001b[0m\n\u001b[0;32m     24\u001b[0m train_classifier(model\u001b[38;5;241m=\u001b[39mSAE_model, epochs\u001b[38;5;241m=\u001b[39mnum_finetuning_epochs, fine_tuning \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, batch_size \u001b[38;5;241m=\u001b[39m batch_size)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Save the model (refer: https://pytorch.org/docs/master/notes/serialization.html)\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSAE_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./models/sae_model.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Git\\kul-anndl-ss24\\.venv\\Lib\\site-packages\\torch\\serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Git\\kul-anndl-ss24\\.venv\\Lib\\site-packages\\torch\\serialization.py:315\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Git\\kul-anndl-ss24\\.venv\\Lib\\site-packages\\torch\\serialization.py:288\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Parent directory ./models does not exist."
          ]
        }
      ],
      "source": [
        "input_dim = 784\n",
        "# Define the autoencoder layers\n",
        "# Try different values for the dimensions of the hidden layers and the number of layers\n",
        "encoder_1 = AutoEncoderLayer(input_dim = input_dim, hidden_dim = 256, SelfTraining=True)\n",
        "encoder_2 = AutoEncoderLayer(input_dim = 256, hidden_dim = 64, SelfTraining=True)\n",
        "\n",
        "encoders_list = [encoder_1, encoder_2]\n",
        "num_layers = len(encoders_list)\n",
        "\n",
        "\n",
        "# Pre-train each layer\n",
        "for level in range(num_layers):\n",
        "   train_layer(layers_list=encoders_list, layer=level, epochs=num_layer_wise_epochs, validate=True, batch_size = batch_size)\n",
        "\n",
        "# Build the stacked autoencoder\n",
        "SAE_model = StackedAutoEncoderClassifier(autoencoder_list=encoders_list, num_classes = 10)\n",
        "# Print the model\n",
        "print(SAE_model)\n",
        "\n",
        "# First train the classification layer\n",
        "train_classifier(model=SAE_model, epochs=num_classifier_epochs, fine_tuning = False, batch_size = batch_size)\n",
        "\n",
        "# Train the whole model and perform fine-tuning\n",
        "train_classifier(model=SAE_model, epochs=num_finetuning_epochs, fine_tuning = True, batch_size = batch_size)\n",
        "\n",
        "\n",
        "# Save the model (refer: https://pytorch.org/docs/master/notes/serialization.html)\n",
        "torch.save(SAE_model, './models/sae_model.pt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
